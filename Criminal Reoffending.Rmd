---
title: "Supervised learning for criminal to reoffend"
author: "Lukas Kaestner"
date: "3/5/20"
output: html_notebook
---


```{r}

library(dplyr)
library(tidyverse)
library(skimr)
library(ggforce)
library(caret) # Tools and common interface to many supervised learning algorithms
library(patchwork) # For combining multiple plots
library(plotROC)
library(pROC)

set.seed(888) # To ensure consistent results from non-deterministic procedures
rm(list = ls()) # Removes all variables


```


# Load data and remove columns with lots of null values
```{r}

compas.df = read_csv("https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores.csv")
head(compas.df)

#compas.df <- select(compas.df, -c("num_r_cases", "num_vr_cases", "vr_case_number", 
  #                                "vr_charge_degree", "vr_offense_date", "vr_charge_desc",
   #                               "r_days_from_arrest", "r_jail_in", "r_jail_out", "r_charge_desc",
   #                               "r_offense_date", "r_case_number", "c_arrest_date", "c_offense_date",
   #                               "c_charge_desc", "name", "first", "last", "id", "compas_screening_date"))

# need to add race and sex
compas.df <- select(compas.df, c("age", "juv_fel_count", "decile_score", 
                                 "juv_misd_count", "juv_other_count", "priors_count",
                                 "days_b_screening_arrest", "c_days_from_compas"))


compas.df <- compas.df %>%
              filter(!is.na(compas.df$days_b_screening_arrest))

colSums(is.na(compas.df))
max(colSums(is.na(compas.df)))


```


```{r}
decile_score_compas.df = compas.df %>% mutate(rec_rate = if_else(decile_score > 5, "bad", "good")) %>% mutate(rec_rate = as.factor(rec_rate))

ggplot(decile_score_compas.df, aes(rec_rate, decile_score, colour = rec_rate, fill = rec_rate)) +
  geom_sina(size = .5, alpha = .7, position = position_jitter(height = 0.1)) +
  labs(x = "Discretized Decile Score", y = "Rated Decile Score") +
  theme(legend.position = "none")
```


# Training and Testing Sets
```{r}

compas.df = decile_score_compas.df %>% select(-decile_score) # Remove numeric indicator of quality

## Creates a random sample of rows for training
inTrain = createDataPartition(compas.df$rec_rate, p = 3/4, list = FALSE) 

## Create dataframes of descriptive variables for training and testing
# Slice extracts rows based on vector of row numbers
trainDescr = compas.df %>% slice(inTrain) %>% select(-rec_rate)
testDescr = compas.df %>% slice(-inTrain) %>% select(-rec_rate)

trainClass = compas.df %>% slice(inTrain) %>% select(rec_rate) %>% as.matrix() %>% as.factor()
testClass = compas.df %>% slice(-inTrain) %>% select(rec_rate) %>% as.matrix() %>% as.factor()

## Proportion of good and bad cases should be the same in testing and training
# Ideally the classes should be balanced
compas.df %>% select(rec_rate) %>%  table() %>% prop.table() %>% round(5)*100 

trainClass %>% table() %>% prop.table() %>% round(5)*100

testClass %>% table() %>% prop.table() %>% round(5)*100
```
There are m ore good outcomes for each but it is not terribly imbalanaced so we can go ahead using this data.



# Pre-processing data by scaling
```{r pre-process, cache=FALSE, warning=FALSE, message=FALSE}

## Trans.mod is a transformation model that is trained and the applied to the data
Trans.mod = preProcess(trainDescr, method = c("center", "scale")) 
trainScaled = predict(Trans.mod, trainDescr)
testScaled = predict(Trans.mod, testDescr)

## Plot transformed data
raw.plot = ggplot(trainDescr, aes(priors_count)) + geom_histogram(bins = 60) +
  labs(title = "Original")

scaled.plot = ggplot(trainScaled, aes(priors_count)) + geom_histogram(bins = 60) +
  labs(title = "Scaled")

(raw.plot / scaled.plot) # Using patchwork package



```



# Tune
```{r tune}

train.control = trainControl(method = "repeatedcv", 
                             number = 10, repeats = 3, # number: number of folds
                             search = "grid", # for tuning hyperparameters
                             classProbs = TRUE, # return probability of prediction
                             savePredictions = "final",
                             summaryFunction = twoClassSummary
                             )

```



# Logistic Regression
```{r train_glm, cache = TRUE, echo=TRUE, warning=FALSE}

glm.fit = train(x = trainScaled, y = trainClass,
   method = 'glm', metric = "ROC",
   trControl = train.control) 

glm.fit

```


# Support Vector Machine
```{r train_svm, cache=TRUE, message=FALSE, warning=FALSE}

grid = expand.grid(C = c(.1, .5, 1))

svm.fit =  train(x = trainScaled, y = trainClass,
  method = "svmLinear", metric = "ROC",
  tuneGrid = grid, # Overrides tuneLength
  tuneLength = 3, # Number of levels of each hyper parameter, unless specified by grid
  trControl = train.control, scaled = TRUE)

plot(svm.fit)

```


# xgboost
```{r train_xgb, cache=TRUE, warning=FALSE, message=FALSE}

xgb.fit = train(x = trainScaled, y = trainClass,
  method = "xgbTree", metric = "ROC",
  tuneLength = 3, # Depends on number of parameters in algorithm
  trControl = train.control, scaled = TRUE)

plot(xgb.fit)

```
The results of the model do not chnage drastically by tuning the hyperparameters for xgboost. The models range from .815 to .825 ROC.



# Compare models
```{r compare_boxplot, cache=TRUE}

mod.resamps = resamples(list(glm = glm.fit, svm = svm.fit, xgb = xgb.fit))

# dotplot(mod.resamps, metric="ROC")

bwplot(mod.resamps, metric = "ROC")

```
XGBoost performed best based on the highest median ROC. Most models, for each type, fell in the .80 to .85 range. 




#Confusion matrix (glm)
```{r assess-glm}

glm.pred = predict(glm.fit, testScaled) 

confusionMatrix(glm.pred, testClass)

```


#Confusion matrix (svm)
```{r assess-svm}

svm.pred = predict(svm.fit, testScaled)

confusionMatrix(svm.pred, testClass)

```


#Confusion matrix (xgb)
```{r assess-xgb}

xgb.pred = predict(xgb.fit, testScaled)

confusionMatrix(xgb.pred, testClass)

```


#ROC plot
```{r assess_ROC, warning=FALSE, message= FALSE}

## Use model to generate predictions
xgb.pred = predict(xgb.fit, testScaled, type = "prob")
glm.pred = predict(glm.fit, testScaled, type = "prob")

## Add prediction and observed to test predictors
predicted.compas.df = decile_score_compas.df %>% slice(-inTrain) %>% 
  cbind(glm.pred.good = glm.pred$good) %>% 
  cbind(xgb.pred.good = xgb.pred$good) %>% 
  cbind(obs = testClass)

## Calculate ROC coordinates and area under curve (AUC)
glm.roc = roc(predictor = predicted.compas.df$glm.pred, 
              response = predicted.compas.df$obs, 
              AUC = TRUE, ci = TRUE)

xgb.roc = roc(predictor = predicted.compas.df$xgb.pred, 
              response = predicted.compas.df$obs, 
              AUC = TRUE, ci = TRUE)

glm.roc$auc
glm.roc$ci


## Plot ROC
xgb_glm.roc.plot =
ggplot(data = predicted.compas.df, aes(d = obs, m = glm.pred.good)) + 
  geom_abline(colour = "grey60") +
  geom_roc(labels = FALSE, linealpha = .5, pointalpha = .5) + # Labels show the predictor value
  geom_roc(aes(d = obs, m = xgb.pred.good),
           labels = FALSE, linealpha = .8, pointalpha = .8) + # Labels show the predictor value
   annotate("text", x = .5, y = .475, hjust = 0,
           label = paste("AUC(xbg) =", round(xgb.roc$auc, 3))) +
   annotate("text", x = .5, y = .375, hjust = 0,
           label = paste("AUC(glm) =", round(glm.roc$auc, 3))) +
  labs(title = "Prediction of whether or not a criminal commits another crime", 
       subtitle = "Extreme gradient boosting predictions (xgboost)") +
  coord_equal() +
  style_roc() 


xgb_glm.roc.plot
ggsave("xgb_glm-roc.png", xgb_glm.roc.plot, width = 5, height = 4.5)


```
I would expect the models to perform worse on the test set. This is because it is easy to overfit data when training and applying that to new data will result in worse performance. However, in reality, the models didn't perform too much worse on the test data than the train data.




## Compare xgboost predictions
```{r xgb-pred-plot}

predicted_wine.plot = 
  ggplot(predicted.compas.df, aes(as.factor(decile_score), xgb.pred.good, colour = rec_rate)) + 
  geom_sina(size = .5) +
  labs(title = "Prediction of criminal committing another crime", 
       subtitle = "Extreme gradient boosting predictions (xgboost)",
       x = "Rated Decile Score",
       y = "Predicted probabilty of no additional crime") +
  theme_gray(base_size = 14) +
  theme(legend.position = "bottom") 
predicted_wine.plot

ggsave(filename = "predicted_wine.png", plot = predicted_wine.plot, 
       width = 5, height = 4.5)

```




